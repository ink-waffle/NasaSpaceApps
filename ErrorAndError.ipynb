{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-08T10:59:41.703203Z",
     "end_time": "2023-10-08T10:59:57.211650Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.manifold import TSNE\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keybert import KeyBERT\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X_df_16 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2016_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, header = None)\n",
    "X_df_16.fillna(0,inplace=True)\n",
    "X_df_17 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2017_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_17.fillna(0,inplace=True)\n",
    "X_df_18 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2018_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_18.fillna(0,inplace=True)\n",
    "X_df_19 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2019_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_19.fillna(0,inplace=True)\n",
    "X_df_20 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2020_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_20.fillna(0,inplace=True)\n",
    "X_df_21 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2021_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_21.fillna(0,inplace=True)\n",
    "X_df_22 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2022_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_22.fillna(0,inplace=True)\n",
    "X_df_23 = pd.read_csv('Datasets/dsc_fc_summed_spectra_2023_v01.csv', delimiter = ',', parse_dates=[0], infer_datetime_format=True, na_values='0', header = None)\n",
    "X_df_23.fillna(0,inplace=True)\n",
    "X_df = [X_df_16, X_df_17, X_df_18, X_df_19, X_df_20, X_df_21]\n",
    "# X_df = [X_df_16]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T10:59:57.211650Z",
     "end_time": "2023-10-08T11:00:17.216086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Y_df = []\n",
    "for i in range(len(X_df)):\n",
    "    with open('Datasets/DGD/' + str(2016 + i) + '_DGD.txt', 'r') as file:\n",
    "        lines = file.readlines()[12:]\n",
    "    days = X_df[i][0].apply(lambda x: \" \".join([x.strftime('%Y'), x.strftime('%m'), x.strftime('%d')])).values\n",
    "    days = set(days)\n",
    "    df = pd.DataFrame(columns=[\"DateTime\", \"MiddleLatitudeA\", \"MiddleLatitudeK\", \"HighLatitudeA\", \"HighLatitudeK\", \"EstimatedPlanetaryA\", \"EstimatedPlanetaryK\"])\n",
    "    for line in lines:\n",
    "        ln = line.replace(\"-\", \" -\").split()\n",
    "        dt = \" \".join(ln[:3])\n",
    "        if dt not in days:\n",
    "            continue\n",
    "        MiddleLatitudeK = list()\n",
    "        HighLatitudeK = list()\n",
    "        EstimatedPlanetaryK = list()\n",
    "        for i in range(8):\n",
    "            df.loc[len(df)] = {\"DateTime\" : (dt + \" \" +str(i*3)), \"MiddleLatitudeA\": int(ln[3]), \"MiddleLatitudeK\": int(ln[4 + i]), \"HighLatitudeA\": int(ln[12]), \"HighLatitudeK\": int(ln[13 + i]), \"EstimatedPlanetaryA\": float(ln[21]), \"EstimatedPlanetaryK\": float(ln[22 + i])}\n",
    "            # MiddleLatitudeK.append(int(ln[4 + i]))\n",
    "            # HighLatitudeK.append(int(ln[13 + i]))\n",
    "            # EstimatedPlanetaryK.append(int(ln[22 + i]))\n",
    "        # Y_df.loc[len(Y_df)] = {\"DateTime\" : (dt + \" \" +str(i*3)), \"MiddleLatitudeA\": ln[3], \"MiddleLatitudeK\": MiddleLatitudeK, \"HighLatitudeA\": ln[12], \"HighLatitudeK\": HighLatitudeK, \"EstimatedPlanetaryA\": ln[21], \"EstimatedPlanetaryK\": MiddleLatitudeK}\n",
    "    Y_df.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T11:00:17.216086Z",
     "end_time": "2023-10-08T11:01:12.394868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_full = pd.concat(X_df)\n",
    "y_full = pd.concat(Y_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T11:01:12.394868Z",
     "end_time": "2023-10-08T11:01:12.748840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class KIndexDataset(Dataset):\n",
    "    def __init__(self, X, y, input_seq_len, output_seq_len):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "\n",
    "        Параметры:\n",
    "            X (pd.DataFrame): Минутные данные признаков.\n",
    "            y (pd.DataFrame): Данные K-index по дням.\n",
    "            input_seq_len (int): Длина входной последовательности.\n",
    "            output_seq_len (int): Длина выходной последовательности (прогноза).\n",
    "        \"\"\"\n",
    "        x_temp = list()\n",
    "        y_temp = list()\n",
    "        # self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        # self.y = torch.tensor([y[0] for y in y.values])\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.output_seq_len = output_seq_len\n",
    "        for i in range(input_seq_len, int(len(y) / 8) - output_seq_len - 1):\n",
    "            x_temp.append(X[1440 * (i - input_seq_len):1440 * (i)].values)\n",
    "            y_temp.append(y[i * 8 : 8 * (i + output_seq_len)].values)\n",
    "        print('a')\n",
    "        self.X = torch.tensor(np.array(x_temp), dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.array(y_temp), dtype=torch.float32)\n",
    "        del x_temp\n",
    "        del y_temp\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета.\n",
    "        \"\"\"\n",
    "        return len(self.X) - self.input_seq_len - self.output_seq_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Возвращает пару (входная последовательность, целевая последовательность) по индексу.\n",
    "\n",
    "        Параметры:\n",
    "            idx (int): Индекс элемента датасета.\n",
    "        \"\"\"\n",
    "        X_seq = self.X[idx]\n",
    "        y_seq = self.y[idx]\n",
    "        return X_seq, y_seq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T04:29:41.523130Z",
     "end_time": "2023-10-08T04:29:41.538766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# Гиперпараметры\n",
    "input_seq_len = 336\n",
    "output_seq_len = 168\n",
    "\n",
    "# Создание экземпляра датасета\n",
    "train_data = KIndexDataset(X_full[[1, 2, 3]], y_full[['EstimatedPlanetaryK']], input_seq_len, output_seq_len)\n",
    "\n",
    "# # # Создание DataLoader\n",
    "# batch_size = 32  # размер батча\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "# tmp = [i for i in iter(train_loader)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T04:29:46.212648Z",
     "end_time": "2023-10-08T04:29:46.397698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "__len__() should return >= 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m  \u001B[38;5;66;03m# размер батча\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m tmp \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(train_loader)]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m--> 351\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    353\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:106\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement, \u001B[38;5;28mbool\u001B[39m):\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    104\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement))\n\u001B[1;32m--> 106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_samples\u001B[49m, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    108\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue, but got num_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:114\u001B[0m, in \u001B[0;36mRandomSampler.num_samples\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnum_samples\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;66;03m# dataset size might change at runtime\u001B[39;00m\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 114\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_source\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples\n",
      "\u001B[1;31mValueError\u001B[0m: __len__() should return >= 0"
     ]
    }
   ],
   "source": [
    "batch_size = 32  # размер батча\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "tmp = [i for i in iter(train_loader)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T03:08:16.754588Z",
     "end_time": "2023-10-08T03:09:14.312480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        _, (hidden, cell) = self.lstm(src)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[1]\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_dim = trg.shape[2]\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_dim).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input = trg[:, t, :] if teacher_force else output\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# Пример использования\n",
    "INPUT_DIM = 3  # размер входного вектора\n",
    "OUTPUT_DIM = 2  # размер выходного вектора\n",
    "ENC_HID_DIM = 64  # размер скрытого состояния в encoder\n",
    "DEC_HID_DIM = 64  # размер скрытого состояния в decoder\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_HID_DIM)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_HID_DIM)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# # Затем вы можете использовать оптимизатор и критерий потерь, подходящие для вашей задачи, чтобы обучить модель.\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.MSELoss()  # Возможно, вы хотите использовать другой критерий потерь, в зависимости от вашей задачи\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T03:08:09.918785Z",
     "end_time": "2023-10-08T03:08:09.992509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "# torch.cpu.empty_cache()\n",
    "\n",
    "# Параметры модели\n",
    "input_dim = 3\n",
    "output_dim = 2\n",
    "enc_hid_dim = 64\n",
    "dec_hid_dim = 64\n",
    "\n",
    "# Инициализация модели, оптимизатора и функции потерь\n",
    "encoder = Encoder(input_dim, enc_hid_dim)\n",
    "decoder = Decoder(output_dim, dec_hid_dim)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(tqdm(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x, y)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-07T22:26:45.322399Z",
     "end_time": "2023-10-07T22:27:53.854355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 16),         1280        ['input_5[0][0]']                \n",
      "                                 (None, 16),                                                      \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 16),   1152        ['input_6[0][0]',                \n",
      "                                 (None, 16),                      'lstm_2[0][1]',                 \n",
      "                                 (None, 16)]                      'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 1)      17          ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,449\n",
      "Trainable params: 2,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def createModel():\n",
    "    # 1. Encoder setup\n",
    "    encoder_inputs = layers.Input(shape=(None, 3))  # 'None' allows for variable sequence length\n",
    "    encoder_lstm = layers.LSTM(16, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # 2. Decoder setup\n",
    "    decoder_inputs = layers.Input(shape=(None, 1))\n",
    "    decoder_lstm = layers.LSTM(16, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = layers.Dense(1, activation='linear')  # Linear activation, but you can use others\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    decoder_state_input_h = layers.Input(shape=(16,))\n",
    "    decoder_state_input_c = layers.Input(shape=(16,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "    decoder_inf_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inf_outputs = decoder_dense(decoder_inf_outputs)\n",
    "\n",
    "    # Construct the model\n",
    "    return keras.Model([encoder_inputs, decoder_inputs], decoder_outputs), keras.Model(encoder_inputs, encoder_states), keras.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_inf_outputs] + decoder_states)\n",
    "\n",
    "model, encoder, decoder = createModel()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=keras.losses.mean_squared_error)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T04:35:54.519056Z",
     "end_time": "2023-10-08T04:35:55.890071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "def decode_sequence(input_seq, input_K):\n",
    "    # Encode the input sequence to get initial states\n",
    "    states_value = encoder.predict(input_seq)\n",
    "\n",
    "    # Generate an empty target sequence with a size of 1.\n",
    "    target_seq = np.zeros((1, 1, 1))  # Assuming 'm' is the dimension of the decoder's output.\n",
    "\n",
    "    # Set the first token of target sequence with the start token.\n",
    "    # Here, you'd typically use a tokenized representation.\n",
    "    # For simplicity, we'll assume you have a function called `start_token_vector` that returns a vector representation of the <start> token.\n",
    "    target_seq[0, 0] = input_K\n",
    "\n",
    "    # Loop to decode the sequence\n",
    "    stop_condition = False\n",
    "    decoded = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample the next token (for simplicity, we're assuming a regression-like task here)\n",
    "        sampled_token_vector = output_tokens[0, -1, :]\n",
    "\n",
    "        decoded.append(sampled_token_vector)\n",
    "\n",
    "        # Exit condition: either hit max length or find the <end> token.\n",
    "        # Here, we'll just use a simple length-based condition for demonstration.\n",
    "        if len(decoded) > 2920:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = np.zeros((1, 1, 1))\n",
    "        target_seq[0, 0] = sampled_token_vector\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T04:31:55.238678Z",
     "end_time": "2023-10-08T04:31:55.265080Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "X, y = X_full[[1, 2, 3]], y_full[['EstimatedPlanetaryK']]\n",
    "input_seq_len = 28*3\n",
    "output_seq_len = 28*1\n",
    "x_temp = list()\n",
    "y_temp = list()\n",
    "for i in range(input_seq_len, int(len(y) / 8) - output_seq_len - 1):\n",
    "    x_temp.append(X[1440 * (i - input_seq_len):1440 * (i)].values)\n",
    "    y_temp.append(y[i * 8: 8 * (i + output_seq_len)].values)\n",
    "print('a')\n",
    "X_train = tf.cast(np.array(x_temp), tf.float16)\n",
    "y_train = tf.cast(np.array(y_temp), tf.float16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T11:02:32.300817Z",
     "end_time": "2023-10-08T11:02:34.731264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 120960, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 16),         1280        ['input_1[0][0]']                \n",
      "                                 (None, 16),                                                      \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 224, 16)      0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 224, 16)      2112        ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][1]',                   \n",
      "                                                                  'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 224, 16)      272         ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 224, 8)       136         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 224, 1)       9           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,809\n",
      "Trainable params: 3,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_seq_length = 120960\n",
    "input_features = 3\n",
    "output_seq_length = 224\n",
    "latent_dim = 16\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = layers.Input(shape=(input_seq_length, input_features))\n",
    "encoder_lstm = layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = layers.RepeatVector(output_seq_length)(encoder_outputs)\n",
    "decoder_lstm = layers.LSTM(latent_dim, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_outputs = layers.Dense(16, activation='relu')(decoder_outputs)\n",
    "decoder_outputs = layers.Dense(8, activation='relu')(decoder_outputs)\n",
    "decoder_outputs = layers.Dense(1, activation='relu')(decoder_outputs)\n",
    "\n",
    "# Construct the model\n",
    "model = tf.keras.Model(encoder_inputs, decoder_outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.1), loss='mse')\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T11:03:17.382430Z",
     "end_time": "2023-10-08T11:03:19.115735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1868s 69s/step - loss: 1.4470\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 2610s 97s/step - loss: 1.4405\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 2735s 102s/step - loss: 1.4349\n",
      "Epoch 4/10\n",
      "18/27 [===================>..........] - ETA: 14:40 - loss: 1.4281"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T04:56:07.853871Z",
     "end_time": "2023-10-08T05:11:16.099426Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model.save('models/model0')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m device_name \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mtest\u001B[38;5;241m.\u001B[39mgpu_device_name()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/device:GPU:0\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m----> 4\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mSystemError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU device not found\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFound GPU at: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(device_name))\n",
      "\u001B[1;31mSystemError\u001B[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
